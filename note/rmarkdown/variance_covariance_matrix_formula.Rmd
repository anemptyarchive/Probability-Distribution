---
title: "分散共分散行列"
author: "@anemptyarchive\\thanks{\\url{https://www.anarchive-beta.com/}}"
date: "`r format(Sys.time(), '%Y-%m-%d %H:%M:%S')`"
output:
  pdf_document:
    latex_engine: xelatex
    number_section: true
    toc: true
    toc_depth: 4
    keep_tex: false
header-includes:
  - \usepackage{bookmark}
  - \usepackage{xltxtra}
  - \usepackage{zxjatype}
  - \usepackage[ipa]{zxjafont}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, 
  message = FALSE, error = FALSE, warning = FALSE, # メッセージを非表示
  fig.align = "center", # 画像を中央揃え
  fig.width = 5, fig.height = 4, # 画像のサイズ
  dev = "cairo_pdf", dev.args = list(family = "ipaexg"), # {ggplot2}に日本語を組み込む場合の対処
  class.source = "numberLines lineAnchors", # ソースを番号付けする
  class.output = "numberLines lineAnchors chunkout" # 出力を番号付けする
)
```

----

【編集履歴】

- 2022/08/27：「相関行列との関係」を追加
- 2022/08/29：「マハラノビス距離との関係」を追加
- 2022/09/03：「固有値・固有ベクトルとの関係」を追加
- 2022/09/04：「固有ベクトルによる分布の回転」を追加

----

\newpage


# 分散共分散行列と相関行列の関係の導出

　分散共分散行列(Variance–Covariance Matrix)と相関行列(Correlation Matrix)の関係を式で確認します。\
\


## 分散共分散行列と相関行列の定義

　まずは、分散共分散行列と相関行列の定義を確認します。\
\

　分散共分散行列は、$D \times D$の正定値行列で定義されます。

$$
\boldsymbol{\Sigma}
    = \begin{pmatrix}
          \sigma_1^2 & \sigma_{1,2} & \cdots & \sigma_{1,D} \\
          \sigma_{2,1} & \sigma_2^2 & \cdots & \sigma_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \sigma_{D,1} & \sigma_{D,2} & \cdots & \sigma_D^2
      \end{pmatrix}
$$

　$D$次元ベクトルの変数を$\mathbf{x} = (x_1, x_2, \cdots, x_D)^{\top}$とすると、$\sigma_d$は$x_d$の標準偏差、$\sigma_d^2 = \sigma_{d,d}$は$x_d$の分散、$\sigma_{i,j} = \sigma_{j,i}$は$x_i, x_j$の共分散です。

$$
\begin{aligned}
\mathrm{s}[x_d]
   &= \sigma_d
\\
\mathbb{V}[x_d]
   &= \sigma_d^2
\\
\mathrm{Cov}[x_i, x_j]
   &= \sigma_{i,j}
\end{aligned}
$$

　1変数の共分散は分散になります。

$$
\mathbb{V}[x_d]
    = \mathrm{Cov}[x_d, x_d]
    = \sigma_{d,d}
    = \sigma_d^2
$$

　共分散を各変数の標準偏差で割ると相関係数になります。

$$
\rho_{i,j}
    = \frac{\sigma_{i,j}}{\sigma_i \sigma_j}
$$

　1変数の相関係数は1になります。

$$
\rho_{d,d}
    = \frac{\sigma_d^2}{\sigma_d \sigma_d}
    = 1
$$

　$D \times D$の相関係数を並べた行列を相関行列と言います。

$$
\mathbf{P}
    = \begin{pmatrix}
          \rho_{1,1} & \rho_{1,2} & \cdots & \rho_{1,D} \\
          \rho_{2,1} & \rho_{2,2} & \cdots & \rho_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \rho_{D,1} & \rho_{D,2} & \cdots & \rho_{D,D}
      \end{pmatrix}
    = \begin{pmatrix}
          1 & \rho_{1,2} & \cdots & \rho_{1,D} \\
          \rho_{2,1} & 1 & \cdots & \rho_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \rho_{D,1} & \rho_{D,2} & \cdots & 1
      \end{pmatrix}
$$

　定義より$\rho_{i,j} = \rho_{j,i}$なので、対称行列です。対角成分は1になります。\
\

　ここまでで、分散共分散行列と相関行列の各成分について確認しました。\
\


## 分散共分散行列と相関行列の変換

　次は、分散共分散行列と相関行列を変換する計算式を確認します。\
\

　$D$個の標準偏差$\sigma_d$を対角成分とする対角行列を$\mathbf{A}$とします。

$$
\mathbf{A}
    = \begin{pmatrix}
          \sigma_1 & 0 & \cdots & 0 \\
          0 & \sigma_2 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \sigma_D
      \end{pmatrix}
$$

　分散共分散行列$\boldsymbol{\Sigma}$は、相関行列$\mathbf{P}$の左右から$\mathbf{A}$を掛けて求められます。

$$
\mathbf{A} \mathbf{P} \mathbf{A}
    = \begin{pmatrix}
          \sigma_1 & 0 & \cdots & 0 \\
          0 & \sigma_2 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \sigma_D
      \end{pmatrix}
      \begin{pmatrix}
          \rho_{1,1} & \rho_{1,2} & \cdots & \rho_{1,D} \\
          \rho_{2,1} & \rho_{2,2} & \cdots & \rho_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \rho_{D,1} & \rho_{D,2} & \cdots & \rho_{D,D}
      \end{pmatrix}
      \begin{pmatrix}
          \sigma_1 & 0 & \cdots & 0 \\
          0 & \sigma_2 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \sigma_D
      \end{pmatrix}
$$

　相関行列の各成分(相関係数)を定義式$\rho_{i,j} = \frac{\sigma_{i,j}}{\sigma_i \sigma_j}$の右辺の形に置き換えて、行列の積を計算します。

$$
\begin{aligned}
\mathbf{A} \mathbf{P} \mathbf{A}
   &= \begin{pmatrix}
          \sigma_1 & 0 & \cdots & 0 \\
          0 & \sigma_2 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \sigma_D
      \end{pmatrix}
      \begin{pmatrix}
          \frac{\sigma_1^2}{\sigma_1 \sigma_1} & 
          \frac{\sigma_{1,2}}{\sigma_1 \sigma_2} & 
          \cdots & 
          \frac{\sigma_{1,D}}{\sigma_1 \sigma_D} \\
          \frac{\sigma_{2,1}}{\sigma_2 \sigma_1} & 
          \frac{\sigma_2^2}{\sigma_2 \sigma_2} & 
          \cdots & 
          \frac{\sigma_{2,D}}{\sigma_2 \sigma_D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \frac{\sigma_{D,1}}{\sigma_D \sigma_1} & 
          \frac{\sigma_{D,2}}{\sigma_D \sigma_2} & 
          \cdots & 
          \frac{\sigma_D^2}{\sigma_D \sigma_D}
      \end{pmatrix}
      \begin{pmatrix}
          \sigma_1 & 0 & \cdots & 0 \\
          0 & \sigma_2 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \sigma_D
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          \frac{\sigma_1 \sigma_1^2}{\sigma_1 \sigma_1} & 
          \frac{\sigma_1 \sigma_{1,2}}{\sigma_1 \sigma_2} & 
          \cdots & 
          \frac{\sigma_1 \sigma_{1,D}}{\sigma_1 \sigma_D} \\
          \frac{\sigma_2 \sigma_{2,1}}{\sigma_2 \sigma_1} & 
          \frac{\sigma_2 \sigma_2^2}{\sigma_2 \sigma_2} & 
          \cdots & 
          \frac{\sigma_2 \sigma_{2,D}}{\sigma_2 \sigma_D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \frac{\sigma_D \sigma_{D,1}}{\sigma_D \sigma_1} & 
          \frac{\sigma_D \sigma_{D,2}}{\sigma_D \sigma_2} & 
          \cdots & 
          \frac{\sigma_D \sigma_D^2}{\sigma_D \sigma_D}
      \end{pmatrix}
      \begin{pmatrix}
          \sigma_1 & 0 & \cdots & 0 \\
          0 & \sigma_2 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \sigma_D
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          \frac{\sigma_1^2}{\sigma_1} & 
          \frac{\sigma_{1,2}}{\sigma_2} & 
          \cdots & 
          \frac{\sigma_{1,D}}{\sigma_D} \\
          \frac{\sigma_{2,1}}{\sigma_1} & 
          \frac{\sigma_2^2}{\sigma_2} & 
          \cdots & 
          \frac{\sigma_{2,D}}{\sigma_D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \frac{\sigma_{D,1}}{\sigma_1} & 
          \frac{\sigma_{D,2}}{\sigma_2} & 
          \cdots & 
          \frac{\sigma_D^2}{\sigma_D}
      \end{pmatrix}
      \begin{pmatrix}
          \sigma_1 & 0 & \cdots & 0 \\
          0 & \sigma_2 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \sigma_D
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          \frac{\sigma_1^2 \sigma_1}{\sigma_1} & 
          \frac{\sigma_{1,2} \sigma_2}{\sigma_2} & 
          \cdots & 
          \frac{\sigma_{1,D} \sigma_D}{\sigma_D} \\
          \frac{\sigma_{2,1} \sigma_1}{\sigma_1} & 
          \frac{\sigma_2^2 \sigma_2}{\sigma_2} & 
          \cdots & 
          \frac{\sigma_{2,D} \sigma_D}{\sigma_D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \frac{\sigma_{D,1} \sigma_1}{\sigma_1} & 
          \frac{\sigma_{D,2} \sigma_2}{\sigma_2} & 
          \cdots & 
          \frac{\sigma_D^2 \sigma_D}{\sigma_D}
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          \sigma_1^2 & \sigma_{1,2} & \cdots & \sigma_{1,D} \\
          \sigma_{2,1} & \sigma_2^2 & \cdots & \sigma_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \sigma_{D,1} & \sigma_{D,2} & \cdots & \sigma_D^2
      \end{pmatrix}
    = \boldsymbol{\Sigma}
\end{aligned}
$$

　行列の積の計算において、各成分は行番号と列番号に対応する次元の項のみが残り、他の項は0によって消えてしまいます。よって、各相関係数に対応した標準偏差が掛けられて分母が打ち消され、分散または共分散になります。\

　続いて、$D$個の標準偏差$\sigma_d$の逆数$\frac{1}{\sigma_d} = \sigma_d^{-1}$を対角成分とする対角行列を$\mathbf{B}$とします。

$$
\mathbf{B}
    = \begin{pmatrix}
          \frac{1}{\sigma_1} & 0 & \cdots & 0 \\
          0 & \frac{1}{\sigma_2} & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \frac{1}{\sigma_D}
      \end{pmatrix}
$$

　相関行列$\mathbf{P}$は、分散共分散行列$\boldsymbol{\Sigma}$の左右から$\mathbf{B}$を掛けて求められます。

$$
\begin{aligned}
\mathbf{B} \boldsymbol{\Sigma} \mathbf{B}
   &= \begin{pmatrix}
          \frac{1}{\sigma_1} & 0 & \cdots & 0 \\
          0 & \frac{1}{\sigma_2} & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \frac{1}{\sigma_D}
      \end{pmatrix}
      \begin{pmatrix}
          \sigma_1^2 & \sigma_{1,2} & \cdots & \sigma_{1,D} \\
          \sigma_{2,1} & \sigma_2^2 & \cdots & \sigma_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \sigma_{D,1} & \sigma_{D,2} & \cdots & \sigma_D^2
      \end{pmatrix}
      \begin{pmatrix}
          \frac{1}{\sigma_1} & 0 & \cdots & 0 \\
          0 & \frac{1}{\sigma_2} & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \frac{1}{\sigma_D}
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          \frac{\sigma_1^2}{\sigma_1} & 
          \frac{\sigma_{1,2}}{\sigma_1} & 
          \cdots & 
          \frac{\sigma_{1,D}}{\sigma_1} \\
          \frac{\sigma_{2,1}}{\sigma_2} & 
          \frac{\sigma_2^2}{\sigma_2} & 
          \cdots & 
          \frac{\sigma_{2,D}}{\sigma_2} \\
          \vdots & \vdots & \ddots & \vdots \\
          \frac{\sigma_{D,1}}{\sigma_D} & 
          \frac{\sigma_{D,2}}{\sigma_D} & 
          \cdots & 
          \frac{\sigma_D^2}{\sigma_D}
      \end{pmatrix}
      \begin{pmatrix}
          \frac{1}{\sigma_1} & 0 & \cdots & 0 \\
          0 & \frac{1}{\sigma_2} & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \frac{1}{\sigma_D}
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          \frac{\sigma_1^2}{\sigma_1 \sigma_1} & 
          \frac{\sigma_{1,2}}{\sigma_1 \sigma_2} & 
          \cdots & 
          \frac{\sigma_{1,D}}{\sigma_1 \sigma_D} \\
          \frac{\sigma_{2,1}}{\sigma_2 \sigma_1} & 
          \frac{\sigma_2^2}{\sigma_2 \sigma_2} & 
          \cdots & 
          \frac{\sigma_{2,D}}{\sigma_2 \sigma_D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \frac{\sigma_{D,1}}{\sigma_D \sigma_1} & 
          \frac{\sigma_{D,2}}{\sigma_D \sigma_2} & 
          \cdots & 
          \frac{\sigma_D^2}{\sigma_D \sigma_D}
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          1 & \rho_{1,2} & \cdots & \rho_{1,D} \\
          \rho_{2,1} & 1 & \cdots & \rho_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \rho_{D,1} & \rho_{D,2} & \cdots & 1
      \end{pmatrix}
    = \mathbf{P}
\end{aligned}
$$

　こちらも、行列の積の計算において各成分に対応する次元の項のみが残り、各共分散に対応した標準偏差の逆数が掛けられ、相関係数になります。\
\

　最後に、2つの計算を別の方法で確認します。\

　対角行列の逆行列は、対角成分の逆数を対角成分とする対角行列になります。よって、$\mathbf{A}$と$\mathbf{B}$は逆行列の関係です。

$$
\mathbf{A}^{-1}
    = \mathbf{B}
$$

　$\mathbf{A}, \mathbf{B}$の積は単位行列$\mathbf{I}$になります。

$$
\begin{aligned}
\mathbf{A} \mathbf{B}
   &= \begin{pmatrix}
          \sigma_1 & 0 & \cdots & 0 \\
          0 & \sigma_2 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \sigma_D
      \end{pmatrix}
      \begin{pmatrix}
          \frac{1}{\sigma_1} & 0 & \cdots & 0 \\
          0 & \frac{1}{\sigma_2} & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \frac{1}{\sigma_D}
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          \frac{\sigma_1}{\sigma_1} & 0 & \cdots & 0 \\
          0 & \frac{\sigma_2}{\sigma_2} & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \frac{\sigma_D}{\sigma_D}
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          1 & 0 & \cdots & 0 \\
          0 & 1 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & 1
      \end{pmatrix}
    = \mathbf{I}
\end{aligned}
$$

　$\mathbf{B} \mathbf{A}$についても同様です。\

　先ほど確認した分散共分散行列の計算式

$$
\boldsymbol{\Sigma}
   = \mathbf{A} \mathbf{P} \mathbf{A}
$$

について、両辺に左右から$\mathbf{B}$を掛けます。

$$
\begin{aligned}
\mathbf{B} \boldsymbol{\Sigma} \mathbf{B}
   &= \mathbf{B} \mathbf{A} \mathbf{P} \mathbf{A} \mathbf{B}
\\
   &= \mathbf{I} \mathbf{P} \mathbf{I}
\\
   &= \mathbf{P}
\end{aligned}
$$

　相関行列の計算式が得られました。\

　同様に、この式の両辺に左右から$\mathbf{A}$を掛けます。

$$
\begin{aligned}
\mathbf{A} \mathbf{P} \mathbf{A}
   &= \mathbf{A} \mathbf{B} \boldsymbol{\Sigma} \mathbf{B} \mathbf{A}
\\
   &= \mathbf{I} \boldsymbol{\Sigma} \mathbf{I}
\\
   &= \boldsymbol{\Sigma}
\end{aligned}
$$

　分散共分散行列の計算式が得られました。\
\

　この記事では、分散共分散行列と相関行列の関係を導出しました。次は、ユークリッド距離・マハラノビス距離との関係を導出します。\
\


# 分散共分散行列とユークリッド距離・マハラノビス距離の関係の導出

　分散共分散行列(Variance–Covariance Matrix)とユークリッド距離(Euclidean Distance)・マハラノビス距離(Mahalanobis Dostance)の関係を導出します。\
\


## 定義式の確認

　まずは、ユークリッド距離とマハラノビス距離の定義式を確認します。\
\

　(確率)変数$\mathbf{x}$を$D$次元ベクトルとすると、平均ベクトル$\boldsymbol{\mu}$は$D$次元ベクトル、分散共分散行列$\boldsymbol{\Sigma}$は$D \times D$の行列になります。

$$
\mathbf{x}
    = \begin{pmatrix}
          x_1 \\
          x_2 \\
          \vdots \\
          x_D
      \end{pmatrix}
,\ 
\boldsymbol{\mu}
    = \begin{pmatrix}
          \mu_1 \\
          \mu_2 \\
          \vdots \\
          \mu_D
      \end{pmatrix}
,\ 
\boldsymbol{\Sigma}
    = \begin{pmatrix}
          \sigma_1^2 & \sigma_{1,2} & \cdots & \sigma_{1,D} \\
          \sigma_{2,1} & \sigma_2^2 & \cdots & \sigma_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \sigma_{D,1} & \sigma_{D,2} & \cdots & \sigma_D^2
      \end{pmatrix}
$$

　$\mu_d$は$x_d$の平均、$\sigma_d$は$x_d$の標準偏差、$\sigma_d^2 = \sigma_{d,d}$は$x_d$の分散、$\sigma_{i,j} = \sigma_{j,i}$は$x_i, x_j$の共分散です。\

　このとき、点$\mathbf{x}$と点$\boldsymbol{\mu}$のユークリッド距離は、次の式で定義されます。

$$
\Delta_{\mathrm{euclid}}
    = \sqrt{
          \sum_{d=1}^D
              (x_d - \mu_d)^2
      }
$$

　$\mathbf{x}, \boldsymbol{\mu}$の各成分の差の平方和の平方根です。\

　また、マハラノビス距離は、次の式で定義定義されます。

$$
\Delta_{\mathrm{mahal}}
    = \sqrt{
          (\mathbf{x} - \boldsymbol{\mu})^{\top}
          \boldsymbol{\Sigma}^{-1}
          (\mathbf{x} - \boldsymbol{\mu})
      }
$$

　$\mathbf{x}, \boldsymbol{\mu}$と$\boldsymbol{\Sigma}$の逆行列の二次形式の平方根です。\

　ユークリッド距離を$\Delta_{\mathrm{euclid}}$、マハラノビス距離を$\Delta_{\mathrm{mahal}}$で表すことにします。\
\


## マハラノビス距離とユークリッド距離の関係

　分散共分散行列が単位行列(変数間に依存関係がない)場合のマハラノビス距離を考えます。\
\

　分散共分散行列$\boldsymbol{\Sigma}$を単位行列$\mathbf{I}$とします。\

$$
\boldsymbol{\Sigma}
    = \begin{pmatrix}
          \sigma_1^2 & \sigma_{1,2} & \cdots & \sigma_{1,D} \\
          \sigma_{2,1} & \sigma_2^2 & \cdots & \sigma_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \sigma_{D,1} & \sigma_{D,2} & \cdots & \sigma_D^2
      \end{pmatrix}
    = \begin{pmatrix}
          1 & 0 & \cdots & 0 \\
          0 & 1 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & 1
      \end{pmatrix}
    = \mathbf{I}
$$

　つまり、各変数の標準偏差と分散が1で、共分散が0です。\

　単位行列の逆行列も単位行列なので、分散共分散行列の逆行列も単位行列になります。

$$
\boldsymbol{\Sigma}
    = \boldsymbol{\Sigma}^{-1}
    = \mathbf{I}
$$

　マハラノビス距離の平方根の中(二次形式)に、単位行列を代入して計算します。

$$
\begin{aligned}
(\mathbf{x} - \boldsymbol{\mu})^{\top}
\boldsymbol{\Sigma}^{-1}
(\mathbf{x} - \boldsymbol{\mu})
   &= \begin{pmatrix}
          x_1 - \mu_1 & x_2 - \mu_2 & \cdots & x_D - \mu_D
      \end{pmatrix}
      \begin{pmatrix}
          1 & 0 & \cdots & 0 \\
          0 & 1 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & 1
      \end{pmatrix}
      \begin{pmatrix}
          x_1 - \mu_1 \\
          x_2 - \mu_2 \\
          \vdots \\
          x_D - \mu_D
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          x_1 - \mu_1 & x_2 - \mu_2 & \cdots & x_D - \mu_D
      \end{pmatrix}
      \begin{pmatrix}
          x_1 - \mu_1 \\
          x_2 - \mu_2 \\
          \vdots \\
          x_D - \mu_D
      \end{pmatrix}
\\
   &= (x_1 - \mu_1)^2
      + (x_2 - \mu_2)^2
      + \cdots
      + (x_D - \mu_D)^2
\\
   &= \sum_{d=1}^D
          (x_d - \mu_d)^2
\end{aligned}
$$

　マハラノビス距離の定義式に代入します。

$$
\begin{aligned}
\Delta_{\mathrm{mahal}}
   &= \sqrt{
          (\mathbf{x} - \boldsymbol{\mu})^{\top}
          \boldsymbol{\Sigma}^{-1}
          (\mathbf{x} - \boldsymbol{\mu})
      }
\\
   &= \sqrt{
          \sum_{d=1}^D
              (x_d - \mu_d)^2
      }
    = \Delta_{\mathrm{euclid}}
\end{aligned}
$$

　分散共分散行列が単位行列のとき、マハラノビス距離がユークリッド距離になるのが分かりました。\
\

　この記事では、分散共分散行列とユークリッド距離・マハラノビス距離の関係を導出しました。次は、固有値・固有ベクトルとの関係を導出します。\
\


# 分散共分散行列と固有値・固有ベクトルの関係の導出

　分散共分散行列(Variance–Covariance Matrix)と固有値(Eigenvalue)・固有ベクトル(Eigenvector)の関係を導出します。\
\


## 固有ベクトル

　まずは、分散共分散行列の固有値と固有ベクトルを確認します。固有値・固有ベクトルの求め方などについては扱いません。\
\

　分散共分散行列は、$D \times D$の正定値行列で定義されます。

$$
\boldsymbol{\Sigma}
    = \begin{pmatrix}
          \sigma_1^2 & \sigma_{1,2} & \cdots & \sigma_{1,D} \\
          \sigma_{2,1} & \sigma_2^2 & \cdots & \sigma_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \sigma_{D,1} & \sigma_{D,2} & \cdots & \sigma_D^2
      \end{pmatrix}
$$

　$D$次元ベクトルの変数を$\mathbf{x} = (x_1, x_2, \cdots, x_D)^{\top}$とすると、$\sigma_d$は$x_d$の標準偏差、$\sigma_d^2 = \sigma_{d,d}$は$x_d$の分散、$\sigma_{i,j} = \sigma_{j,i}$は$x_i, x_j$の共分散です。\

　分散共分散行列$\boldsymbol{\Sigma}$は正定値行列なので、固有ベクトルの方程式が成り立ちます。

$$
\boldsymbol{\Sigma} \mathbf{u}_i
    = \lambda_i \mathbf{u}_i
\tag{2.45}
$$

　$\lambda_i$を固有値、$\mathbf{u}_i$を固有ベクトルと言い、$\mathbf{u}_i$は$D$次元ベクトルです。

$$
\mathbf{u}_i
    = \begin{pmatrix}
          u_{i,1} \\
          u_{i,2} \\
          \vdots \\
          u_{i,D}
      \end{pmatrix}
$$

　$i = 1, 2, \dots, D$の$D$個の固有ベクトル$\mathbf{u}_i^{\top}$を行とする(行方向に並べた)$D \times D$の行列を$\mathbf{U}$で表します。

$$
\mathbf{U}
    = \begin{pmatrix}
          \mathbf{u}_1^{\top} \\
          \mathbf{u}_2^{\top} \\
          \vdots \\
          \mathbf{u}_D^{\top}
      \end{pmatrix}
    = \begin{pmatrix}
          \begin{pmatrix}
              u_{1,1} & u_{1,2} & \cdots & u_{1,D}
          \end{pmatrix} \\
          \begin{pmatrix}
              u_{2,1} & u_{2,2} & \cdots & u_{2,D}
          \end{pmatrix} \\
          \vdots \\
          \begin{pmatrix}
              u_{D,1} & u_{D,2} & \cdots & u_{D,D}
          \end{pmatrix}
      \end{pmatrix}
    = \begin{pmatrix}
          u_{1,1} & u_{1,2} & \cdots & u_{1,D} \\
          u_{2,1} & u_{2,2} & \cdots & u_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{D,1} & u_{D,2} & \cdots & u_{D,D}
      \end{pmatrix}
$$

　$\mathbf{U}$の$i$行目が$\mathbf{u}_i^{\top}$に対応します。\
　$\mathbf{U}$の転置行列は、$\mathbf{u}_i$を列とする(列方向に並べた)行列です。

$$
\mathbf{U}^{\top}
    = \begin{pmatrix}
          \mathbf{u}_1 & \mathbf{u}_2 & \cdots & \mathbf{u}_D
      \end{pmatrix}
    = \begin{pmatrix}
          \begin{pmatrix}
              u_{1,1} \\ u_{1,2} \\ \vdots \\ u_{1,D}
          \end{pmatrix} &
          \begin{pmatrix}
              u_{2,1} \\ u_{2,2} \\ \vdots \\ u_{2,D}
          \end{pmatrix} &
          \cdots &
          \begin{pmatrix}
              u_{D,1} \\ u_{D,2} \\ \vdots \\ u_{D,D}
          \end{pmatrix}
      \end{pmatrix}
    = \begin{pmatrix}
          u_{1,1} & u_{2,1} & \cdots & u_{D,1} \\
          u_{1,2} & u_{2,2} & \cdots & u_{D,2} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{1,D} & u_{2,D} & \cdots & u_{D,D}
      \end{pmatrix}
$$

　$\mathbf{U}^{\top}$の$i$列目が$\mathbf{u}_i$に対応します。\
\


## 固有ベクトルの性質

　次は、固有ベクトルの性質を導出します。\
\

　分散共分散行列は正定値行列なので、2つの固有ベクトル$\mathbf{u}_i, \mathbf{u}_j$の内積は、0か1の値をとります。(元の行列が実対称行列のとき、異なる($i \neq j$の)固有ベクトルの内積は1になります。)


\begin{align*}
\mathbf{u}_i^{\top} \mathbf{u}_j
   &= \begin{pmatrix}
          u_{i,1} & u_{i,2} \cdots & u_{i,D}
      \end{pmatrix}
      \begin{pmatrix}
          u_{j,1} \\
          u_{j,2} \\
          \vdots \\
          u_{j,D}
      \end{pmatrix}
\\
   &= u_{i,1} u_{j,1}
      + u_{i,2} u_{j,2}
      + \cdots
      + u_{i,D} u_{j,D}
\\
   &= \sum_{d=1}^D
          u_{i,d} u_{j,d}
    = I_{i,j}
\tag{2.46}
\end{align*}


　$\{0, 1\}$の2値をとるので単位行列の成分$I_{i,j}$で表します。

$$
\mathbf{u}_i^{\top} \mathbf{u}_j
    = I_{i,j}
    = \begin{cases}
          1 &\quad (i = j) \\
          0 &\quad (i \neq j)
      \end{cases}
\tag{2.47}
$$

　$I_{i,j}$は、$i = j$のとき1、$i \neq j$のとき0になります。よって、異なる($i \neq j$の)固有ベクトルは直交します(直角に交わります)。\

　$\mathbf{U}, \mathbf{U}^{\top}$の行列の積は、単位行列$\mathbf{I}$になります。

$$
\begin{aligned}
\mathbf{U} \mathbf{U}^{\top}
   &= \begin{pmatrix}
          u_{1,1} & u_{1,2} & \cdots & u_{1,D} \\
          u_{2,1} & u_{2,2} & \cdots & u_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{D,1} & u_{D,2} & \cdots & u_{D,D}
      \end{pmatrix}
      \begin{pmatrix}
          u_{1,1} & u_{2,1} & \cdots & u_{D,1} \\
          u_{1,2} & u_{2,2} & \cdots & u_{D,2} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{1,D} & u_{2,D} & \cdots & u_{D,D}
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          \sum_{d=1}^D u_{1,d} u_{1,d} & 
          \sum_{d=1}^D u_{1,d} u_{2,d} & 
          \cdots & 
          \sum_{d=1}^D u_{1,d} u_{D,d} \\
          \sum_{d=1}^D u_{2,d} u_{1,d} & 
          \sum_{d=1}^D u_{2,d} u_{2,d} & 
          \cdots & 
          \sum_{d=1}^D u_{2,d} u_{D,d} \\
          \vdots & \vdots & \ddots & \vdots \\
          \sum_{d=1}^D u_{D,d} u_{1,d} & 
          \sum_{d=1}^D u_{D,d} u_{2,d} & 
          \cdots & 
          \sum_{d=1}^D u_{D,d} u_{D,d}
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          I_{1,1} & I_{1,2} & \cdots & I_{1,D} \\
          I_{2,1} & I_{2,2} & \cdots & I_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          I_{D,1} & I_{D,2} & \cdots & I_{D,D}
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          1 & 0 & \cdots & 0 \\
          0 & 1 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & 1
      \end{pmatrix}
    = \mathbf{I}
\end{aligned}
$$

　各成分の計算が式(2.46)に対応していて、対角成分が($i = j$のとき)1、それ以外の成分が($i \neq j$のとき)0になります。\
　この計算を、$\mathbf{u}_i$を並べた表現の行列でも行ってみます。

$$
\begin{aligned}
\mathbf{U} \mathbf{U}^{\top}
   &= \begin{pmatrix}
          \mathbf{u}_1^{\top} \\
          \mathbf{u}_2^{\top} \\
          \vdots \\
          \mathbf{u}_D^{\top}
      \end{pmatrix}
      \begin{pmatrix}
          \mathbf{u}_1 & \mathbf{u}_2 & \cdots & \mathbf{u}_D
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          \mathbf{u}_1^{\top} \mathbf{u}_1 & 
          \mathbf{u}_1^{\top} \mathbf{u}_2 & 
          \cdots & 
          \mathbf{u}_1^{\top} \mathbf{u}_D \\
          \mathbf{u}_2^{\top} \mathbf{u}_1 & 
          \mathbf{u}_2^{\top} \mathbf{u}_2 & 
          \cdots & 
          \mathbf{u}_2^{\top} \mathbf{u}_D \\
          \vdots & \vdots & \ddots & \vdots \\
          \mathbf{u}_D^{\top} \mathbf{u}_1 & 
          \mathbf{u}_D^{\top} \mathbf{u}_2 & 
          \cdots & 
          \mathbf{u}_D^{\top} \mathbf{u}_D
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          I_{1,1} & I_{1,2} & \cdots & I_{1,D} \\
          I_{2,1} & I_{2,2} & \cdots & I_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          I_{D,1} & I_{D,2} & \cdots & I_{D,D}
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          1 & 0 & \cdots & 0 \\
          0 & 1 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & 1
      \end{pmatrix}
    = \mathbf{I}
\end{aligned}
$$

　こちらも、各成分が式(2.46)に対応しているのが分かります。\

　単位行列$\mathbf{I}$は対角行列なので、転置しても単位行列$\mathbf{I} = \mathbf{I}^{\top}$です。よって、$\mathbf{U}^{\top} \mathbf{U}$を転置しても単位行列になります。

$$
\mathbf{U} \mathbf{U}^{\top}
    = (\mathbf{U} \mathbf{U}^{\top})^{\top}
    = \mathbf{U}^{\top} \mathbf{U}
    = \mathbf{I}
$$

　行列の性質$(\mathbf{A}^{\top} \mathbf{B})^{\top} = \mathbf{A} \mathbf{B}^{\top}$を使って変形しました。\
　つまり、$\mathbf{U}$と$\mathbf{U}^{\top}$の積は掛ける順番に関わらず単位行列になります。

$$
\mathbf{U} \mathbf{U}^{\top}
    = \mathbf{U}^{\top} \mathbf{U}
    = \mathbf{I}
$$

　このような行列を直交行列と言います。\

　2つ目の等式の両辺に右から$\mathbf{U}$の逆行列を掛けます。

$$
\begin{aligned}
\mathbf{U}^{\top} \mathbf{U}
   &= \mathbf{I}
\\
\Leftrightarrow
\mathbf{U}^{\top} \mathbf{U} \mathbf{U}^{-1}
   &= \mathbf{I} \mathbf{U}^{-1}
\\
\Leftrightarrow
\mathbf{U}^{\top} \mathbf{I}
   &= \mathbf{U}^{-1}
\\
\Leftrightarrow
\mathbf{U}^{\top}
   &= \mathbf{U}^{-1}
\end{aligned}
$$

　逆行列の定義$\mathbf{A} \mathbf{A}^{-1} = \mathbf{I}$により変形しました。\
　直交行列は転置行列と逆行列が等しくなります。

$$
\mathbf{U}^{\top}
    = \mathbf{U}^{-1}
$$

\ 

　$\mathbf{U}^{\top} \mathbf{U} = \mathbf{I}$の計算を確認します。

$$
\begin{aligned}
\mathbf{U}^{\top} \mathbf{U}
   &= \begin{pmatrix}
          u_{1,1} & u_{2,1} & \cdots & u_{D,1} \\
          u_{1,2} & u_{2,2} & \cdots & u_{D,2} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{1,D} & u_{2,D} & \cdots & u_{D,D}
      \end{pmatrix}
      \begin{pmatrix}
          u_{1,1} & u_{1,2} & \cdots & u_{1,D} \\
          u_{2,1} & u_{2,2} & \cdots & u_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{D,1} & u_{D,2} & \cdots & u_{D,D}
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          \sum_{i=1}^D u_{i,1}^2 & 
          \sum_{i=1}^D u_{i,1} u_{i,2} & 
          \cdots & 
          \sum_{i=1}^D u_{i,1} u_{i,D} \\
          \sum_{i=1}^D u_{i,2} u_{i,1} & 
          \sum_{i=1}^D u_{i,2}^2 & 
          \cdots & 
          \sum_{i=1}^D u_{i,2} u_{i,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \sum_{i=1}^D u_{i,D} u_{i,1} & 
          \sum_{i=1}^D u_{i,D} u_{i,2} & 
          \cdots & 
          \sum_{i=1}^D u_{i,D}^2
      \end{pmatrix}
\end{aligned}
$$

　この行列が単位行列になるので

$$
\begin{aligned}
\mathbf{U}^{\top} \mathbf{U}
   &= \begin{pmatrix}
          I_{1,1} & I_{1,2} & \cdots & I_{1,D} \\
          I_{2,2} & I_{2,2} & \cdots & I_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          I_{D,1} & I_{D,2} & \cdots & I_{D,D}
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          1 & 0 & \cdots & 0 \\
          0 & 1 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & 1
      \end{pmatrix}
    = \mathbf{I}
\end{aligned}
$$

となります。($\sum_{i=1}^D u_{i,k} u_{i,l} = I_{k,l}$になる理由を知りたいけど分からなかった。)\
　この計算も$\mathbf{u}_i$を並べた行列のまま計算してみます。

$$
\begin{aligned}
\mathbf{U}^{\top} \mathbf{U}
   &= \begin{pmatrix}
          \mathbf{u}_1 & \mathbf{u}_2 & \cdots & \mathbf{u}_D
      \end{pmatrix}
      \begin{pmatrix}
          \mathbf{u}_1^{\top} \\
          \mathbf{u}_2^{\top} \\
          \vdots \\
          \mathbf{u}_D^{\top}
      \end{pmatrix}
\\
   &= \sum_{i=1}^D
          \mathbf{u}_i \mathbf{u}_i^{\top}
\end{aligned}
$$

　$\mathbf{u}_i, \mathbf{u}_i^{\top}$のベクトルの積は

$$
\begin{aligned}
\mathbf{u}_i \mathbf{u}_i^{\top}
   &= \begin{pmatrix}
          u_{i,1} \\
          u_{i,2} \\
          \vdots \\
          u_{i,D}
      \end{pmatrix}
      \begin{pmatrix}
          u_{i,1} & u_{i,2} & \cdots & u_{i,D}
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          u_{i,1}^2 & u_{i,1} u_{i,2} & \cdots & u_{i,1} u_{i,D} \\
          u_{i,2} u_{i,1} & u_{i,2}^2 & \cdots & u_{i,2} u_{i,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{i,D} u_{i,1} & u_{i,D} u_{i,2} & \cdots & u_{i,D}^2
      \end{pmatrix}
\end{aligned}
$$

となるので、これを代入します。

$$
\begin{aligned}
\mathbf{U}^{\top} \mathbf{U}
   &= \sum_{i=1}^D
          \begin{pmatrix}
              u_{i,1}^2 & u_{i,1} u_{i,2} & \cdots & u_{i,1} u_{i,D} \\
              u_{i,2} u_{i,1} & u_{i,2}^2 & \cdots & u_{i,2} u_{i,D} \\
              \vdots & \vdots & \ddots & \vdots \\
              u_{i,D} u_{i,1} & u_{i,D} u_{i,2} & \cdots & u_{i,D}^2
          \end{pmatrix}
\\
   &= \begin{pmatrix}
          u_{1,1}^2 & u_{1,1} u_{1,2} & \cdots & u_{1,1} u_{1,D} \\
          u_{1,2} u_{1,1} & u_{1,2}^2 & \cdots & u_{1,2} u_{1,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{1,D} u_{1,1} & u_{1,D} u_{1,2} & \cdots & u_{1,D}^2
      \end{pmatrix}
      + \begin{pmatrix}
          u_{2,1}^2 & u_{2,1} u_{2,2} & \cdots & u_{2,1} u_{2,D} \\
          u_{2,2} u_{2,1} & u_{2,2}^2 & \cdots & u_{2,2} u_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{2,D} u_{2,1} & u_{2,D} u_{2,2} & \cdots & u_{2,D}^2
        \end{pmatrix} \\
   &\qquad
      + \cdots
      + \begin{pmatrix}
          u_{D,1}^2 & u_{D,1} u_{D,2} & \cdots & u_{D,1} u_{D,D} \\
          u_{D,2} u_{D,1} & u_{D,2}^2 & \cdots & u_{D,2} u_{D,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{D,D} u_{D,1} & u_{D,D} u_{D,2} & \cdots & u_{D,D}^2
        \end{pmatrix}
\\
   &= \begin{pmatrix}
          \sum_{i=1}^D u_{i,1}^2 & 
          \sum_{i=1}^D u_{i,1} u_{i,2} & 
          \cdots & 
          \sum_{i=1}^D u_{i,1} u_{i,D} \\
          \sum_{i=1}^D u_{i,2} u_{i,1} & 
          \sum_{i=1}^D u_{i,2}^2 & 
          \cdots & 
          \sum_{i=1}^D u_{i,2} u_{i,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \sum_{i=1}^D u_{i,D} u_{i,1} & 
          \sum_{i=1}^D u_{i,D} u_{i,2} & 
          \cdots & 
          \sum_{i=1}^D u_{i,D}^2
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          I_{1,1} & I_{1,2} & \cdots & I_{1,D} \\
          I_{2,2} & I_{2,2} & \cdots & I_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          I_{D,1} & I_{D,2} & \cdots & I_{D,D}
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          1 & 0 & \cdots & 0 \\
          0 & 1 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & 1
      \end{pmatrix}
    = \mathbf{I}
\end{aligned}
$$

　式展開の途中に出てきた次の関係を次節で使います。

$$
\mathbf{U}^{\top} \mathbf{U}
    = \sum_{i=1}^D
          \mathbf{u}_i \mathbf{u}_i^{\top}
    = \mathbf{I}
\tag{1}
$$          

\ 


## 分散共分散行列と固有値・固有ベクトル

　固有ベクトルの性質を確認できたので、分散共分散行列と固有値・固有ベクトルの関係を導出します。\
\

　固有ベクトルの方程式(2.45)を考えます。

$$
\boldsymbol{\Sigma} \mathbf{u}_i
    = \lambda_i \mathbf{u}_i
\tag{2.45}
$$

　両辺に、右から$\mathbf{u}_i^{\top}$を掛けます。

$$
\boldsymbol{\Sigma} \mathbf{u}_i \mathbf{u}_i^{\top}
    = \lambda_i \mathbf{u}_i \mathbf{u}_i^{\top}
$$

　(見やすいように両辺を入れ替えて、)両辺で$i$について1から$D$まで和をとります。

$$
\begin{aligned}
\sum_{i=1}^D
    \lambda_i
    \mathbf{u}_i \mathbf{u}_i^{\top}
   &= \sum_{i=1}^D
          \boldsymbol{\Sigma}
          \mathbf{u}_i \mathbf{u}_i^{\top}
\\
   &= \boldsymbol{\Sigma}
      \sum_{i=1}^D
          \mathbf{u}_i \mathbf{u}_i^{\top}
\end{aligned}
$$

　$\boldsymbol{\Sigma}$は$i$と無関係なので、$\sum_i$の外に出せます。\
　先ほど確認した式(1)より、右辺は$\boldsymbol{\Sigma}$になります。

$$
\begin{aligned}
\sum_{i=1}^D
    \lambda_i
    \mathbf{u}_i \mathbf{u}_i^{\top}
   &= \boldsymbol{\Sigma}
      \mathbf{I}
\\
   &= \boldsymbol{\Sigma}
\end{aligned}
$$

　よって、(両辺を再度入れ替えると)次の式が成り立ちます。

$$
\boldsymbol{\Sigma}
    = \sum_{i=1}^D
        \lambda_i
        \mathbf{u}_i \mathbf{u}_i^{\top}
\tag{2.48}
$$

　固有値と固有ベクトルの積の和によって、分散共分散行列を表せました。\

　式(2.48)の右辺を展開して、行列の積に分解します。

$$
\begin{aligned}
\boldsymbol{\Sigma}
   &= \begin{pmatrix}
          \sum_{i=1}^D \lambda_i u_{i,1}^2 & 
          \sum_{i=1}^D \lambda_i u_{i,1} u_{i,2} & 
          \cdots & 
          \sum_{i=1}^D \lambda_i u_{i,1} u_{i,D} \\
          \sum_{i=1}^D \lambda_i u_{i,2} u_{i,1} & 
          \sum_{i=1}^D \lambda_i u_{i,2}^2 & \
          \cdots & 
          \sum_{i=1}^D \lambda_i u_{i,2} u_{i,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \sum_{i=1}^D \lambda_i u_{i,D} u_{i,1} & 
          \sum_{i=1}^D \lambda_i u_{i,D} u_{i,2} & 
          \cdots & 
          \sum_{i=1}^D \lambda_i u_{i,D}^2
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          \lambda_1 u_{1,1} & 
          \lambda_2 u_{2,1} & 
          \cdots & 
          \lambda_D u_{D,1} \\
          \lambda_1 u_{1,2} & 
          \lambda_2 u_{2,2} & 
          \cdots & 
          \lambda_D u_{D,2} \\
          \vdots & \vdots & \ddots & \vdots \\
          \lambda_1 u_{1,D} & 
          \lambda_2 u_{2,D} & 
          \cdots & 
          \lambda_D u_{D,D}
      \end{pmatrix}
      \begin{pmatrix}
          u_{1,1} & u_{1,2} & \cdots & u_{1,D} \\
          u_{2,1} & u_{2,2} & \cdots & u_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{D,1} & u_{D,2} & \cdots & u_{D,D}
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          u_{1,1} & u_{2,1} & \cdots & u_{D,1} \\
          u_{1,2} & u_{2,2} & \cdots & u_{D,2} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{1,D} & u_{2,D} & \cdots & u_{D,D}
      \end{pmatrix}
      \begin{pmatrix}
          \lambda_1 & 0 & \cdots & 0 \\
          0 & \lambda_2 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \lambda_D
      \end{pmatrix}
      \begin{pmatrix}
          u_{1,1} & u_{1,2} & \cdots & u_{1,D} \\
          u_{2,1} & u_{2,2} & \cdots & u_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{D,1} & u_{D,2} & \cdots & u_{D,D}
      \end{pmatrix}
\\
   &= \mathbf{U}^{\top} \boldsymbol{\Lambda} \mathbf{U}
\end{aligned}
$$

　$D$個の固有値$\lambda_i$を対角成分とする対角行列を$\boldsymbol{\Lambda}$とおきました(精度行列ではありません)。

$$
\boldsymbol{\Lambda}
    = \begin{pmatrix}
          \lambda_1 & 0 & \cdots & 0 \\
          0 & \lambda_2 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \lambda_D
      \end{pmatrix}
$$

　固有値による行列と固有ベクトルによる行列の積によって、分散共分散行列を表せました。\
\

　もう一度、固有ベクトルの方程式を考えます。

$$
\boldsymbol{\Sigma} \mathbf{u}_i
    = \lambda_i \mathbf{u}_i
\tag{2.45}
$$

　両辺に、左から$\boldsymbol{\Sigma}$の逆行列と$\lambda_i$の逆数を掛けて、左辺の$\boldsymbol{\Sigma}$と右辺の$\lambda_i$を打ち消します。

$$
\begin{aligned}
\frac{1}{\lambda_i}
\boldsymbol{\Sigma}^{-1} \boldsymbol{\Sigma}
\mathbf{u}_i
   &= \frac{1}{\lambda_i} \lambda_i
      \boldsymbol{\Sigma}^{-1} \mathbf{u}_i
\\
\Leftrightarrow
\frac{1}{\lambda_i} \mathbf{I} \mathbf{u}_i
   &= \boldsymbol{\Sigma}^{-1} \mathbf{u}_i
\\
\Leftrightarrow
\frac{1}{\lambda_i} \mathbf{u}_i
   &= \boldsymbol{\Sigma}^{-1} \mathbf{u}_i
\end{aligned}
$$

　さらに、右から$\mathbf{u}_i^{\top}$を掛けます。

$$
\frac{1}{\lambda_i}
\mathbf{u}_i \mathbf{u}_i^{\top}
    = \boldsymbol{\Sigma}^{-1}
      \mathbf{u}_i \mathbf{u}_i^{\top}
$$

　両辺で$i$について1から$D$まで和をとると、式(1)より右辺は$\boldsymbol{\Sigma}$の逆行列になります。

$$
\begin{aligned}
\sum_{i=1}^D
    \frac{1}{\lambda_i}
    \mathbf{u}_i \mathbf{u}_i^{\top}
   &= \boldsymbol{\Sigma}^{-1}
      \sum_{i=1}^D
          \mathbf{u}_i \mathbf{u}_i^{\top}
\\
   &= \boldsymbol{\Sigma}^{-1}
      \mathbf{I}
\\
   &= \boldsymbol{\Sigma}^{-1}
\end{aligned}
$$

　よって、(両辺を入れ替えると)次の式が成り立ちます。

$$
\boldsymbol{\Sigma}^{-1}
    = \sum_{i=1}^D
          \frac{1}{\lambda_i}
          \mathbf{u}_i \mathbf{u}_i^{\top}
\tag{2.49}
$$

　分散共分散行列の逆行列も、固有値と固有ベクトルで表せました。\

　式(2.49)の右辺を展開して、行列の積に分解します。

$$
\begin{aligned}
\boldsymbol{\Sigma}^{-1}
   &= \begin{pmatrix}
          \sum_{i=1}^D \frac{1}{\lambda_i} u_{i,1}^2 & 
          \sum_{i=1}^D \frac{1}{\lambda_i} u_{i,1} u_{i,2} & 
          \cdots & 
          \sum_{i=1}^D \frac{1}{\lambda_i} u_{i,1} u_{i,D} \\
          \sum_{i=1}^D \frac{1}{\lambda_i} u_{i,2} u_{i,1} & 
          \sum_{i=1}^D \frac{1}{\lambda_i} u_{i,2}^2 & \
          \cdots & 
          \sum_{i=1}^D \frac{1}{\lambda_i} u_{i,2} u_{i,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \sum_{i=1}^D \frac{1}{\lambda_i} u_{i,D} u_{i,1} & 
          \sum_{i=1}^D \frac{1}{\lambda_i} u_{i,D} u_{i,2} & 
          \cdots & 
          \sum_{i=1}^D \frac{1}{\lambda_i} u_{i,D}^2
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          \frac{1}{\lambda_1} u_{1,1} & 
          \frac{1}{\lambda_2} u_{2,1} & 
          \cdots & 
          \frac{1}{\lambda_D} u_{D,1} \\
          \frac{1}{\lambda_1} u_{1,2} & 
          \frac{1}{\lambda_2} u_{2,2} & 
          \cdots & 
          \frac{1}{\lambda_D} u_{D,2} \\
          \vdots & \vdots & \ddots & \vdots \\
          \frac{1}{\lambda_1} u_{1,D} & 
          \frac{1}{\lambda_2} u_{2,D} & 
          \cdots & 
          \frac{1}{\lambda_D} u_{D,D}
      \end{pmatrix}
      \begin{pmatrix}
          u_{1,1} & u_{1,2} & \cdots & u_{1,D} \\
          u_{2,1} & u_{2,2} & \cdots & u_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{D,1} & u_{D,2} & \cdots & u_{D,D}
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          u_{1,1} & u_{2,1} & \cdots & u_{D,1} \\
          u_{1,2} & u_{2,2} & \cdots & u_{D,2} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{1,D} & u_{2,D} & \cdots & u_{D,D}
      \end{pmatrix}
      \begin{pmatrix}
          \frac{1}{\lambda_1} & 0 & \cdots & 0 \\
          0 & \frac{1}{\lambda_2} & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \frac{1}{\lambda_D}
      \end{pmatrix}
      \begin{pmatrix}
          u_{1,1} & u_{1,2} & \cdots & u_{1,D} \\
          u_{2,1} & u_{2,2} & \cdots & u_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{D,1} & u_{D,2} & \cdots & u_{D,D}
      \end{pmatrix}
\\
   &= \mathbf{U}^{\top} \boldsymbol{\Lambda}^{-1} \mathbf{U}
\end{aligned}
$$

　$D$個の固有値の逆数$\frac{1}{\lambda_i}$を対角成分とする対角行列は、$\boldsymbol{\Lambda}$の逆行列です。

$$
\boldsymbol{\Lambda}^{-1}
    = \begin{pmatrix}
          \frac{1}{\lambda_1} & 0 & \cdots & 0 \\
          0 & \frac{1}{\lambda_2} & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \frac{1}{\lambda_D}
      \end{pmatrix}
$$

　対角行列の逆行列は、対角成分の逆数を対角成分とする対角行列になります。\
　固有値(の逆数)による行列と固有ベクトルによる行列の積によって、分散共分散行列の逆行列を表せました。\
\

　この記事では、分散共分散行列と固有値・固有ベクトルの関係を導出しました。次は、固有ベクトルによるガウス分布の回転を導出します。\
\


# 分散共分散行列の固有ベクトルによるガウス分布の回転の導出

　分散共分散行列(Variance–Covariance Matrix)の固有ベクトル(Eigenvector)による多次元ガウス分布(Multivariate Gaussian Distribution)・多変量正規分布(Multivariate Normal Distribution)の回転を導出します。\
\


## 式の確認

　まずは、これまでに扱った式を確認します。\
\

　多次元ガウス分布は、次の式で定義されます。詳しくは「多次元ガウス分布の定義式」を参照してください。

$$
\mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \boldsymbol{\Sigma})
    = \frac{1}{\sqrt{(2 \pi)^D |\boldsymbol{\Sigma}|}}
      \exp \left\{
          - \frac{1}{2}
            (\mathbf{x} - \boldsymbol{\mu})^{\top}
            \boldsymbol{\Sigma}^{-1}
            (\mathbf{x} - \boldsymbol{\mu})
      \right\}
$$

　ここで、$\boldsymbol{\mu}$は平均ベクトル、$\boldsymbol{\Sigma}$は分散共分散行列、$\pi$は円周率です。また、$\mathbf{A}^{\top}$は転置行列、$\mathbf{A}^{-1}$は逆行列、$|\mathbf{A}|$は行列式です。\
　$\mathbf{x}, \boldsymbol{\mu}$は$D$次元ベクトル、$\boldsymbol{\Sigma}$は$D \times D$の行列です。

$$
\mathbf{x}
    = \begin{pmatrix}
          x_1 \\
          x_2 \\
          \vdots \\
          x_D
      \end{pmatrix}
,\ 
\boldsymbol{\mu}
    = \begin{pmatrix}
          \mu_1 \\
          \mu_2 \\
          \vdots \\
          \mu_D
      \end{pmatrix}
,\ 
\boldsymbol{\Sigma}
    = \begin{pmatrix}
          \sigma_1^2 & \sigma_{1,2} & \cdots & \sigma_{1,D} \\
          \sigma_{2,1} & \sigma_2^2 & \cdots & \sigma_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          \sigma_{D,1} & \sigma_{D,2} & \cdots & \sigma_D^2
      \end{pmatrix}
$$

　$\sigma_d$は$x_d$の標準偏差、$\sigma_d^2 = \sigma_{d,d}$は$x_d$の分散、$\sigma_{i,j} = \sigma_{j,i}$は$x_i, x_j$の共分散です。$\boldsymbol{\Sigma}$は正定値行列を満たす必要があります。\
\

　分散共分散行列$\boldsymbol{\Sigma}$は、$i = 1, 2, \dots, D$の$D$個の固有値$\lambda_i$と固有ベクトル$\mathbf{u}_i = (u_{i,1}, u_{i,2}, \cdots, u_{i,D})^{\top}$を持ちます。詳しくは「分散共分散行列と固有値・固有ベクトルの関係の導出」を参照してください。\
　$D$個の固有値を対角要素とする行列を$\boldsymbol{\Lambda}$、固有ベクトルを行とする行列を$\mathbf{U}$で表します。($\boldsymbol{\Lambda}$は精度行列ではありません。)

$$
\boldsymbol{\Lambda}
    = \begin{pmatrix}
          \lambda_1 & 0 & \cdots & 0 \\
          0 & \lambda_2 & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \lambda_D
      \end{pmatrix}
,\ 
\mathbf{U}
    = \begin{pmatrix}
          u_{1,1} & u_{1,2} & \cdots & u_{1,D} \\
          u_{2,1} & u_{2,2} & \cdots & u_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{D,1} & u_{D,2} & \cdots & u_{D,D}
      \end{pmatrix}
$$

　$D$個の固有値の逆数$\frac{1}{\lambda_i}$を対角成分とする対角行列は、$\boldsymbol{\Lambda}$の逆行列です。

$$
\boldsymbol{\Lambda}^{-1}
    = \begin{pmatrix}
          \frac{1}{\lambda_1} & 0 & \cdots & 0 \\
          0 & \frac{1}{\lambda_2} & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \frac{1}{\lambda_D}
      \end{pmatrix}
$$

　対角行列の逆行列は、対角成分の逆数を対角成分とする対角行列になります。\
　$\mathbf{U}$は直交行列なので、転置行列$\mathbf{U}^{\top}$と逆行列$\mathbf{U}^{-1}$が一致します。

$$
\mathbf{U}^{\top}
    = \mathbf{U}^{-1}
$$

　また、$\mathbf{U}$と転置行列の積は単位行列$\mathbf{I}$になります。

$$
\mathbf{U} \mathbf{U}^{\top}
    = \mathbf{U}^{\top} \mathbf{U}
    = \mathbf{I}
$$

\ 

　以降は、固有値・固有ベクトルを用いて、ガウス分布の定義式を変形して、回転後のガウス分布の式を求めます。\
\


## 二次形式の変換

　次は、ガウス分布の指数部分を考えます。\
\

　指数部分の二次形式を$\Delta^2$とおきます。(この記事の内容との関係は薄いですが、マハラノビス距離については「マハラノビス距離との関係」を参照してください。)

$$
\Delta^2
    = (\mathbf{x} - \boldsymbol{\mu})^{\top}
      \boldsymbol{\Sigma}^{-1}
      (\mathbf{x} - \boldsymbol{\mu})
\tag{2.44}
$$

　この式の$\boldsymbol{\Sigma}$の逆行列に、前回求めた

$$
\boldsymbol{\Sigma}^{-1}
    = \sum_{i=1}^D
        \frac{1}{\lambda_i}
        \mathbf{u}_i \mathbf{u}_i^{\top}
\tag{2.49}
$$

を代入します。

$$
\Delta^2
    = \sum_{i=1}^D
          \frac{1}{\lambda_i}
          (\mathbf{x} - \boldsymbol{\mu})^{\top}
          \mathbf{u}_i \mathbf{u}_i^{\top}
          (\mathbf{x} - \boldsymbol{\mu})
$$


　$(\mathbf{x} - \boldsymbol{\mu})^{\top} \mathbf{u}_i$は、スカラになるので転置しても影響しません。

$$
(\mathbf{x} - \boldsymbol{\mu})^{\top} \mathbf{u}_i
    = \{(\mathbf{x} - \boldsymbol{\mu})^{\top} \mathbf{u}_i\}^{\top}
    = \mathbf{u}_i^{\top}
      (\mathbf{x} - \boldsymbol{\mu})
$$

　この因子を


\begin{align*}
y_i
   &= \mathbf{u}_i^{\top}
      (\mathbf{x} - \boldsymbol{\mu})
\tag{2.51}\\
   &= \begin{pmatrix}
          u_{i,1} & u_{i,2} & \cdots & u_{i,D}
      \end{pmatrix}
      \begin{pmatrix}
          x_1 - \mu_1 \\
          x_2 - \mu_2 \\
          \vdots \\
          x_D - \mu_D
      \end{pmatrix}
\\
   &= u_{i,1} (x_1 - \mu_1)
      + u_{i,2} (x_2 - \mu_2)
      + \cdots
      + u_{i,D} (x_D - \mu_D)
\\
   &= \sum_{d=1}^D
          u_{i,d} (x_d - \mu_d)
\end{align*}


とおき、式(2.44)を変形した式に代入します。


\begin{align*}
\Delta^2
   &= \sum_{i=1}^D
          \frac{1}{\lambda_i}
          \mathbf{u}_i^{\top}
          (\mathbf{x} - \boldsymbol{\mu})
          \mathbf{u}_i^{\top}
          (\mathbf{x} - \boldsymbol{\mu})
\\
   &= \sum_{i=1}^D
          \frac{1}{\lambda_i}
          y_i y_i
\\
   &= \sum_{i=1}^D
          \frac{y_i^2}{\lambda_i}
\tag{2.50}
\end{align*}


　$i = 1, 2, \dots, D$の$D$個の$y_i$は、$\mathbf{U}$を用いて計算できます。


\begin{align*}
\mathbf{y}
   &= \mathbf{U}
    (\mathbf{x} - \boldsymbol{\mu})
\tag{2.52}\\
   &= \begin{pmatrix}
          u_{1,1} & u_{1,2} & \cdots & u_{1,D} \\
          u_{2,1} & u_{2,2} & \cdots & u_{2,D} \\
          \vdots & \vdots & \ddots & \vdots \\
          u_{D,1} & u_{D,2} & \cdots & u_{D,D}
      \end{pmatrix}
      \begin{pmatrix}
          x_1 - \mu_1 \\
          x_2 - \mu_2 \\
          \vdots \\
          x_D - \mu_D
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          \sum_{d=1}^D u_{1,d} (x_d - \mu_d) \\
          \sum_{d=1}^D u_{2,d} (x_d - \mu_d) \\
          \vdots \\
          \sum_{d=1}^D u_{D,d} (x_d - \mu_d)
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          y_1 \\
          y_2 \\
          \vdots \\
          y_D
      \end{pmatrix}
\end{align*}


　二次形式(2.50)を$\mathbf{y}$を用いた式に変形します。


\begin{align*}
\Delta^2
   &= \sum_{i=1}^D
          \frac{y_i^2}{\lambda_i}
\tag{2.50}\\
   &= \begin{pmatrix}
          \frac{y_1}{\lambda_1} & \frac{y_2}{\lambda_2} & \cdots & \frac{y_D}{\lambda_D}
      \end{pmatrix}
      \begin{pmatrix}
          y_1 \\
          y_2 \\
          \vdots \\
          y_D
      \end{pmatrix}
\\
   &= \begin{pmatrix}
          y_1 & y_2 & \cdots & y_D
      \end{pmatrix}
      \begin{pmatrix}
          \frac{1}{\lambda_1} & 0 & \cdots & 0 \\
          0 & \frac{1}{\lambda_2} & \cdots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
          0 & 0 & \cdots & \frac{1}{\lambda_D}
      \end{pmatrix}
      \begin{pmatrix}
          y_1 \\
          y_2 \\
          \vdots \\
          y_D
      \end{pmatrix}
\\
   &= \mathbf{y}^{\top} \boldsymbol{\Lambda}^{-1} \mathbf{y}
\tag{1}
\end{align*}


　元の分布の二次形式が、$\mathbf{y}$と$\boldsymbol{\Lambda}$による二次形式になりました。\
\


## 分散共分散行列の変換

　続いて、分散共分散行列の行列式を考えます。\
\

　$\mathbf{U}$と$\boldsymbol{\Lambda}$による$\boldsymbol{\Sigma}$の計算式(2.48)を考えます。

$$
\boldsymbol{\Sigma}
    = \sum_{i=1}^D
          \lambda_i \mathbf{u}_i \mathbf{u}_i^{\top}
    = \mathbf{U}^{\top} \boldsymbol{\Lambda} \mathbf{U}
\tag{2.48}
$$

　両辺の行列式をとります。

$$
\begin{aligned}
|\boldsymbol{\Sigma}|
   &= |\mathbf{U}^{-1} \boldsymbol{\Lambda} \mathbf{U}|
\\
   &= |\mathbf{U}^{-1}| |\boldsymbol{\Lambda}| |\mathbf{U}|
\\
   &= |\mathbf{U}|^{-1} |\boldsymbol{\Lambda}| |\mathbf{U}|
\\
   &= |\boldsymbol{\Lambda}|
\end{aligned}
$$

　行列式の性質$|\mathbf{A} \mathbf{B}| = |\mathbf{A}| |\mathbf{B}|$、$|\mathbf{A}^{-1}| = |\mathbf{A}|^{-1}$、$|\mathbf{A}|^{-1} = \frac{1}{|\mathbf{A}|}$より、変形しました。行列式はスカラなので掛ける順番を入れ替えられます。\
　また、対角行列の行列式は対角成分の総乗になります。

$$
|\boldsymbol{\Sigma}|
    =|\boldsymbol{\Lambda}|
    = \prod_{i=1}^D
          \lambda_i
\tag{2}
$$

　分散共分散行列の行列式は、$D$個の固有値の積で計算できるのが分かりました。\
\


## ガウス分布の変換

　必要な因子を変形できたので、次は定義式全体を変形します。\
\

　ガウス分布の定義式に式(1,2)を代入して、$\mathbf{y}$の分布$p(\mathbf{y})$とおきます。

$$
p(\mathbf{y})
    = \frac{1}{\sqrt{(2 \pi)^D |\boldsymbol{\Lambda}|}}
      \exp \left\{
          - \frac{1}{2}
            \mathbf{y} \boldsymbol{\Lambda}^{-1} \mathbf{y}
      \right\}
    = \mathcal{N}(\mathbf{y} | \mathbf{0}, \boldsymbol{\Lambda})
$$

　$p(\mathbf{y})$は、平均ベクトルが$\mathbf{0} = (0, \cdots, 0)^{\top}$、分散共分散行列が$\boldsymbol{\Lambda}$の$D$次元ガウス分布で表せます。\

　さらに、行列の項をスカラの項に置き換えます。


\begin{align*}
p(\mathbf{y})
   &= \frac{1}{\sqrt{(2 \pi)^D \prod_{i'=1}^D \lambda_{i'}}}
      \exp \left(
          - \frac{1}{2}
            \sum_{i=1}^D
          \frac{y_i^2}{\lambda_i}
      \right)
\tag{2.56}\\
   &= \prod_{i'=1}^D
          \frac{1}{\sqrt{2 \pi \lambda_i}}
          \exp \left(
              - \frac{y_i^2}{2 \lambda_i}
          \right)
\\
   &= \sum_{i=1}^D
          \mathcal{N}(y_i | 0, \lambda_i)
\tag{2.56}
\end{align*}


　$p(\mathbf{y})$は、平均が0、分散が$\lambda_i$の$D$個の1次元ガウス分布の積で表せます。この式変形については「多次元ガウス分布の定義式」の「変数間に依存関係がない場合」を参照してください。\

　以上で、固有ベクトルにより並行移動して回転した分布が得られました。\
\

　この記事では、分散共分散行列の固有ベクトルによるガウス分布の回転を導出しました。\
\
